\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
%\usepackage{fullpage}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{algorithmic}
\usepackage{wrapfig}

\title{CS263: HW \#6}
\author{Ben Lickly}
\date{March 30, 2010}

\newcommand{\problem}[1]
{\subsubsection*{} %\fbox{\parbox{\textwidth}{
\vspace{-16pt} \section{} \vspace{-22pt} \qquad
#1%}}
\bigskip \bigskip
}

\newcommand{\while}[2]{\operatorname{while}\, #1\ \operatorname{do}\ #2}
\newcommand{\ifthen}[3]{\operatorname{if}\, #1\ \operatorname{then}\ #2\ \operatorname{else}\ #3}
\newcommand{\denote}[1]{\llbracket #1 \rrbracket}
\newcommand{\proves}{\vdash}
\newcommand{\axiomatic}[3]{\{#1\}\ #2\ \{#3\}}
\newcommand{\meet}{\bigwedge}
\newcommand{\powerset}{\mathcal{P}}
\newcommand{\glb}{\operatorname{glb}}

\begin{document}
\maketitle

\problem{Show the encoding of the predecessor function in lambda-calculus, using
the encoding of natural numbers that we have given in class. The predecessor of 0
should be 0. Please do not write your solution as a big mess of lambdas. Use
intermediate functions (like we did for $add$ and $succ$) that make it easy to
understand how your encoding works.
}

For this problem, I will create a new numeric type called $newnat$ that extends
the old natural numbers with a notion for $-1$.  The idea is then to define
predecessor as applying the $newnat$'s successor function to $-1$ $n$ times.

In the following definitions, the argument $n$ will refer to the old style of
natural numbers and the argument $m$ will refer to the new type.
\begin{align*}
newneg1 = mkpair true 0 \\
newnat n = mkpair false n \\
oldnat m = snd m \\
newsucc m = (fst m) (newnat 0) (newnat (succ (oldnat m))) \\
pred n = oldnat (n newsucc newneg1)
\end{align*}

\problem{Show how you can encode lists in lambda-calculus. Show the encoding of
$nil$ (empty list), $cons$ (prepend an element to a list), $length$ (return the
natural number representing the length of a list), and $append$. Please keep it
simple.
}

We can play the same trick that numbers do where a list is an object that we
give a function and an object and it repeatedly applies the function. This
time, however, the function will also need to look at the contents of the list,
so it will be a two argument function rather than a one argument one.

\[
nil = 0
\]

\[
cons x l = \lambda f \lambda s.  f x (l f s)
\]


\[
length l = l (\lambda x \lambda y. succ y) 0
\]

\[
append l1 l2 = \lambda f \lambda s. l1 f (l2 f s)
\]

\problem{Show that the execution always terminates in the call-by-value
simply-typed $\lambda$-calculus. You need to consider only variables, integer
constants, addition, abstraction and application. If you use induction, state
precisely on what you induct.
}

Rather than simply pove inductively that every program or program fragment will
always terminates, we will prove a stronger property, that I will call
\emph{strong termination}.  Informally, a program fragment that strongly
terminates terminates with a value itself will strongly terminate if given a
valid value.  The formal definition of strong termination will be a recursive
definition:

We say that a program fragment $e_1$ strongly terminates, or $ST(e_1)$, if
$e_1$ terminates and either $e_1$ has a primitive type ($int$ or $bool$)
or
\[
e : (\tau_1 \to \tau_2) \quad \text{ and }
\quad ST(e_2: \tau_1) \implies ST(e e_2 : \tau_2)
\]

The proof that any program fragment strongly terminates in the call-by-value
simply-typed $lamba$-calculus will be on the structure of the typing judgement,
just like the definition of strong termination itself.

Here our base case will be constants, such as integer constants.
By our definition of $ST$, it is clear that $ST(a)$ for any primitive constant:
\[
\frac{}{ST(a)}
\]

Since a free variable cannot be run at all, we cannot say whether a variable
by itself will terminate.  We will deal with the variables in the program by 
making an assumption that they terminate when they are introduced in the
abstraction rule.

In the case of addition, we know that the result is an integer, which is a
primitive type.  Thus, to prove strong termination, all we need to prove is
regular termination. Here, we can simply use our induction hypothesis
to break the typing judgement into smaller pieces, since the sum of two halting
expressions will always halt:
\[
\frac{ST(e_1) \qquad ST(e_1)}
{ST(e_1 + e_2)}
\]

In the case of abstraction, we use the induction hypothesis to first prove that
the body of the function strongly terminates.  For this sub-derivation, we can
use the assumption that the variable introduced in this abstraction strongly
terminates.  We will need that assumption, since we don't have any separate
rule for proving that variables strongly terminate.
Note that this assumption that the argument to the resulting lambda expression
terminates is exactly the assumption provided for in the definition of strong
termination.
\[
\frac{ST(x) \implies ST(e)}
{\lambda x:\tau_1. e \Downarrow \lambda x:\tau_1. e
\ \wedge\ ST(\lambda x:\tau_1.e) }
\]

In the  case of application, we use our induction hypothesis twice.  We can
then rely on the properties of strong termination to know that the application
of two strongly terminating values will terminate to a strongly terminating
value.
\[
\frac{ST(e_1)\ \wedge\ e_1 \Downarrow \lambda x:\tau_2. e_1'
\qquad
ST(e_2)\ \wedge\ e_2 \Downarrow v_2 }
{e_1 e_2 \Downarrow [v_2/x]e_1' \ \wedge\ ST(e_1 e_2)}
\]

\end{document}
